<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>basicAI</title>
    <link href="/2023/02/06/basicAI/"/>
    <url>/2023/02/06/basicAI/</url>
    
    <content type="html"><![CDATA[<h1 id="Basical-AI-notes"><a href="#Basical-AI-notes" class="headerlink" title="Basical AI notes"></a>Basical AI notes</h1><h6 id="tags-notes-AI-Basic"><a href="#tags-notes-AI-Basic" class="headerlink" title="tags: notes AI Basic"></a>tags: <code>notes</code> <code>AI</code> <code>Basic</code></h6><p>CS188课程翻译笔记：<br><a href="https://zhuanlan.zhihu.com/p/61895500">知乎|翻译1</a>；<a href="https://zhuanlan.zhihu.com/p/64368643">知乎|翻译2</a>；<a href="https://zhuanlan.zhihu.com/p/148256240">知乎|翻译3</a>；<a href="https://zhuanlan.zhihu.com/p/272652797">知乎|翻译4</a>；原版笔记资料<a href="https://inst.eecs.berkeley.edu/~cs188/sp21/">CS188|Introduction to Artificial Intelligence</a>.<br><img src="https://picx.zhimg.com/80/v2-8b04444c0088fea1efa9778f0dfc2dbb_1440w.webp?source=1940ef5c"></p><h1 id="1-search"><a href="#1-search" class="headerlink" title="1.search"></a>1.search</h1><h2 id="1-1-Agent"><a href="#1-1-Agent" class="headerlink" title="1.1 Agent"></a>1.1 Agent</h2><p>在人工智能中，主要问题是建立一个rational（理性的）的agent，一个<strong>有特定目标或偏好</strong>并会针对这些目标试图<strong>执行一系列操作（action）</strong> 来得到<strong>最优解的实体</strong>（即一个理性<strong>决策者</strong>）环境和agent一起组成了一个<strong>世界</strong></p><h3 id="Reflex-Agent"><a href="#Reflex-Agent" class="headerlink" title="Reflex Agent"></a>Reflex Agent</h3><p><a href="https://en.wikipedia.org/wiki/Intelligent_agent">wiki|intelligent agent</a><br>感知代理(IA).根据当前感知(或者记忆)选择行动<br>可能拥有世界当前状态的记忆或模型<br><strong>不考虑他们行为的未来后果，只是根据世界的当前状态而选择一个操作</strong>；何谓AI，感知其环境，自主采取行动以实现目标，并且可以通过学习或使用知识来提高其性能的任何东西；核心即<strong>目标导向行为视为智能的本质</strong>；<br>其Consider how <strong>the world is</strong></p><h3 id="Planning-Agent"><a href="#Planning-Agent" class="headerlink" title="Planning Agent"></a>Planning Agent</h3><p>有一个世界模型并用这个模型来模拟执行不同的操作，能够确定操作的假想结果并依据此选择最佳操作，即实现<strong>预测</strong><br>Consider how the world <strong>would be</strong><br>have a model of how the world evolves in response to actions；其预测决策、行为的后果</p><hr><h2 id="1-2-State-Spaces-and-Search-Problems-状态空间和搜索问题"><a href="#1-2-State-Spaces-and-Search-Problems-状态空间和搜索问题" class="headerlink" title="1.2 State Spaces and Search Problems 状态空间和搜索问题"></a>1.2 State Spaces and Search Problems 状态空间和搜索问题</h2><h3 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h3><p>首先给出概念定义：</p><ul><li><strong>搜索问题</strong>：给定agent的当前状态（state）（它在环境中的配置），我们如何尽可能最好地达到一个满足目标的新状态</li><li><strong>状态空间state space</strong>：在给定世界中所有可能的状态</li><li><strong>后继函数successor function</strong>：参数包含一个状态和一个操作，并计算执行该操作的<strong>代价</strong>（cost）和执行操作后世界的<strong>后继状态</strong></li><li><strong>起始状态start state</strong>：agent最初存在时当前世界的状态</li><li><strong>目标测试函数goal test</strong>：一个函数，输入一个状态并决定它是否是一个目标状态（是否在<strong>目标集</strong>中）</li><li><strong>世界状态world state</strong>：包含一个给定状态的所有信息</li><li><strong>搜索状态search state</strong>：仅包含对计划（主要是为了空间效率）必要的信息</li></ul><p>示例介绍：本课程使用<strong>吃豆人Pacman游戏</strong>做示例。吃豆人必须探索一个迷宫，吃掉所有的的小豆子并且不被游荡的恶灵吃掉。如果它吃了大豆子，它将在一段时间内无敌并且能吃掉恶灵赚取分</p><p>解决搜索问题的步骤：</p><ol><li>考虑它的起始状态</li><li>用后继函数探索它的状态空间</li><li>反复计算不同状态的后继直到后继为目标状态</li></ol><p>此时建立起<strong>计划路径</strong>连接起始与目标；在解决搜索过程中，由<strong>策略strategy</strong>来决定探索不同状态的顺序。</p><h3 id="世界状态与搜索状态"><a href="#世界状态与搜索状态" class="headerlink" title="世界状态与搜索状态"></a>世界状态与搜索状态</h3><p><em><strong>示例搜索问题</strong></em>迷宫中只有吃豆人和豆子。在这种情况下我们能给出两种不同的搜索问题：路径规划和光盘行动（pathing and eat-all-dots）。路径规划需要找出从位置$(x_1,y_1)$到$(x_2,y_2)$的最佳方案，而光盘行动要求用尽可能短的时间吃掉迷宫中所有的豆子。<img src="https://pic3.zhimg.com/80/v2-0fed5f8a8af2ae536cbe65db806d1dc6_720w.webp"></p><p>路径规划的状态包含的信息比光盘行动要少，因为在光盘行动中我们必须保存一大批布尔值用来表示在给定状态中每个豆子有没有被吃掉。一个世界状态还有可能包含更多的信息，比如吃豆人走过的总距离，或者吃豆人在它的当前位置（x，y）和豆子布尔值上到达过的所有地方这些潜在的编码信息。</p><p>简而言之，世界状态是整个世界中所有的信息，而<strong>搜索状态是对于一个搜索问题其所有需要输入的信息</strong>。</p><h3 id="State-Space-Size-状态空间大小"><a href="#State-Space-Size-状态空间大小" class="headerlink" title="State Space Size 状态空间大小"></a>State Space Size 状态空间大小</h3><p>状态空间大小可以用于<strong>估算搜索问题运行时间</strong>，其唯一计算方法：<br>如果在一个给定的世界里有n个变量分别有$x_1,x_2,x_3…$种不同的取值，那么状态的总数为$x_1x_2x_3x_4…$。</p><p><em><strong>示例</strong></em>：我们用吃豆人来举例说明这个概念，吃豆人有120个位置，前进方向有4个，恶灵有两个，每个恶灵有12个可能位置，共有30个豆子，每个豆子有被吃或未被吃两种状态。则总状态空间大小$120\times4\times12^2\times2^{30}$</p><h3 id="State-Space-Graphs-and-Search-Trees-状态空间图和搜索树"><a href="#State-Space-Graphs-and-Search-Trees-状态空间图和搜索树" class="headerlink" title="State Space Graphs and Search Trees 状态空间图和搜索树"></a>State Space Graphs and Search Trees 状态空间图和搜索树</h3><p>上述示例用了四个部件来完整地定义了一个状态空间。<br><strong>状态空间图（state space graph）</strong> 是由代表状态的结点以及从一个状态指向其后继的有向边构成的。这些边表示操作（action），而任何相关联的权重表示对应操作的代价。每个结点的状态都包括了上述4个元素。<br><strong>注意：</strong> 状态空间图中每个状态只表示一次。</p><p>而对于<strong>搜索树</strong>，其对一个状态的出现次数没有限制。例如，空间图中的极长S → d → e → r → f → G，其在对应搜索树中反映为<strong>从根节点到叶子结点的一个道路</strong>。由于从一个状态到另一个状态通常会有多种方案，搜索树中状态会出现多次。<code>简言之</code>，搜索树中呈现的是搜索路径而不只是结点和结点间关系。<br><img src="https://pic3.zhimg.com/80/v2-4477c7076b96e2ff6609ddcb9e5cfc0e_720w.webp"></p><p>一般在搜索问题中，我们只保存即刻处理的状态，并用相应的后继函数根据需求来计算新的状态。</p><blockquote><p>在树中，我们每次观察那几个非常小心地存储选择的节点，反复地用其后继来替换节点，直到我们到达一个目标状态。</p></blockquote><p>下面将介绍一些方法来决定搜索树中迭代替换结点的顺序（即不同的策略strategy）。</p><h2 id="Uninformed-Search-未知搜索"><a href="#Uninformed-Search-未知搜索" class="headerlink" title="Uninformed Search 未知搜索"></a>Uninformed Search 未知搜索</h2><p>首先介绍<strong>树搜索tree search</strong>：</p><blockquote><p>通过移除一个与部分计划对应的节点（用给定的策略来选择）并用它所有的子节点代替它，我们不断地扩展（expand）我们的边缘(outer fringe)。用子节点代替边缘上的元素,相当于丢弃一个长度为n的计划并考虑所有源于它的长度为（n+1）的计划。我们继续这一操作，直到最终将目标从边缘移除为止。此时我们得出结论，<strong>与移除的目标状态相对应的部分计划其实就是从起始状态到目标状态的一条路径</strong>。</p></blockquote><p>当我们不知道目标状态在搜索树中的的位置时，我们只能从属于<strong>未知搜索（uninformed search）</strong> 的技术中选择用于树搜索的策略。我们将依次介绍<strong>三种策略</strong>：深度优先搜索DFS、广度优先搜索BFS和一致代价搜索UCS，同时包括搜索策略的基本性质，包括完备性、最优性、分支因数h、最大深度m，最浅解深度s</p><h3 id="DFS深度优先搜索"><a href="#DFS深度优先搜索" class="headerlink" title="DFS深度优先搜索"></a>DFS深度优先搜索</h3><p>何为<strong>边缘</strong>，即是当前探索道路的两端（如果不算根的话，即是探索的“头”，多个道路可以有多个头）</p><ul><li><strong>描述</strong>：深度优先搜索DFS总是<strong>选择距离起始节点最深的边缘节点来进行扩展</strong>。DFS选择先访问邻接结点的邻接结点。</li><li><strong>边缘表示</strong>：DFS在边缘将最深结点移除后让最深结点的孩子结点<strong>成为边缘</strong>，此时孩子结点的深度即是<code>原最深结点深度+1</code>。即<strong>边缘中最近添加的对象总有最高优先级</strong>，使用栈（后进先出LIFO）来进行存储。</li><li><strong>完备性</strong>：深度优先搜索<strong>并不具有完备性</strong>。如果在状态空间图中存在回路，这必然意味着相应搜索树的<strong>深度将是无限的</strong>（搜索树是空间图中极长道路组成的，空间图存在回路也就是没有极长道路了）。因此，存在这样一种可能性，即DFS老实地在无限大的搜索树中搜索最深的节点而不幸地陷入僵局，注定无法找到解。</li><li><strong>最优性</strong>：深度优先搜索只是在搜索树中找到“最左边”的解，而没有考虑路径的代价，因此不是最优的。DFS先检索的是邻接表中的第一个邻接结点，<strong>可能有解但不一定是最优解</strong></li><li><strong>时间复杂度</strong>：在最坏情况下，深度优先搜索最终可能会搜遍整个搜索树。</li><li><strong>空间复杂度</strong>：在最坏情况下，DFS在边缘上m个深度级别上都有b个节点。这是一个简单的结果，因为一旦某个父节点的b个子节点进入队列，DFS的本性在任意时间点都只允许研究任意一个子节点的一棵子树。即为$O(bm)$</li></ul><h3 id="BFS广度优先搜索"><a href="#BFS广度优先搜索" class="headerlink" title="BFS广度优先搜索"></a>BFS广度优先搜索</h3><ul><li><strong>描述</strong>：宽度优先搜索总是<strong>选择距离起始节点最浅（近）的边缘节点来扩展</strong>。BFS选择先访问完全所有的邻接结点。</li><li><strong>边缘表示</strong>：如果我们想在较深的节点之前访问较浅的节点，我们必须按照节点的插入顺序来访问它们。使用队列（先进先出FIFO）。</li><li><strong>完备性</strong>：由于总是访问最浅边缘结点，而<strong>最浅结点深度一定是有限的</strong>（在存在解的前提下），故一定可以搜索下去而不会进入死循环，故完备。</li><li><strong>最优性</strong>：BFS一般不是最优的，因为它在选择边缘上被替换的节点时不会考虑代价问题。在所有边的代价都相等的特殊情况下BFS可以保证是最优的，因为这会让BFS退化为一致代价搜索。</li><li><strong>时间复杂度</strong>：遍历所有结点</li><li><strong>空间复杂度</strong>：在最坏情况下，边缘所有节点都在对应最浅解的那一层。（全都要存，都要朝下面找）</li></ul><h3 id="Uniform-Cost-Search-一致代价搜索"><a href="#Uniform-Cost-Search-一致代价搜索" class="headerlink" title="Uniform Cost Search 一致代价搜索"></a>Uniform Cost Search 一致代价搜索</h3><ul><li><strong>描述</strong>：UCS总是选择距离起始节点代价（边权）最小的边缘节点来扩展。</li><li><strong>边缘表示</strong>：UCS的边缘选择用优先堆（<strong>小顶堆</strong>），对于其中的结点v其权重即为从起始节点到v的路径代价，称之为<strong>v的后退代价backward cost</strong>。</li><li><strong>完备性</strong>：如果存在一个目标状态v，它一定有从根到v的有限长度最短路径。故完备</li><li><strong>最优性</strong>：当所有边权非负，UCS是最优的（按照路径代价递增的顺序搜索结点）</li><li><strong>时间复杂度</strong>：<blockquote><p>我们定义最优路径代价为$C^*$，状态空间图内两节点之间最小代价为$\varepsilon$。那么，我们得简单粗暴地遍历深度为从1到$\frac{C^*}{\varepsilon}$范围内的所有节点，导致运行时间为$O\left( b^{\frac{C^*}{\varepsilon}} \right)$。</p></blockquote></li></ul><p>注意：上述三种搜索策略<strong>本质都是树搜索</strong>，只是策略的不同。</p><h2 id="Informed-Search有信息搜索"><a href="#Informed-Search有信息搜索" class="headerlink" title="Informed Search有信息搜索"></a>Informed Search有信息搜索</h2><p>UCS在完备性和最优性上很棒，但时间复杂度较高。如果我们对于我们应该搜索的方向有一定的了解，我们就能显著提高性能并更快地达到目标。这就是有信息搜索。<strong>即已知目标位置，可以估算到目标的距离</strong>。</p><h3 id="Heuristics-启发式搜索"><a href="#Heuristics-启发式搜索" class="headerlink" title="Heuristics 启发式搜索"></a>Heuristics 启发式搜索</h3><p>首先介绍启发式搜索的定义：</p><blockquote><p>Heuristics are the driving force that allow <strong>estimation（估计） of distance to goal states</strong> - they（启发式搜索）’re functions that take in a state as input and output a corresponding estimate. 以一个状态作为输入，以相应的估计为输出。</p></blockquote><p>启发式搜索这种函数是专门用来解决搜索问题的，</p><blockquote><p>we usually want heuristic functions to be a lower bound on this remaining distance to the goal。我们希望启发式搜索可以获得剩余到目标距离的下限，因而启发式搜索通常处理<strong>relaxed problems</strong>。</p></blockquote><p><em><strong>示例</strong></em>：对于前面的路径规划问题，通用解决方法是<strong>曼哈顿距离法Manhattan Distance</strong>。定义两点间曼哈顿距离为：$Manhattan(x_1,y_1,x_2,y_2)&#x3D;|x_1-x_2|+|y_1-y_2|$<br><img src="https://pic4.zhimg.com/80/v2-c3949a1c7834e55745aff852d46447e3_720w.webp" alt="image alt"></p><p>假想要到达左下角，它在计算了<strong>假设没有墙</strong>的情况下从吃豆人现在的位置到目标位置的距离。这个距离是松弛搜索问题中的<strong>精确（exact）距离</strong>，而相应的在实际的搜索问题中计算出的是<strong>估计（estimated）目标距离</strong>。从而实现了为agent<strong>建立“偏好拓展状态”的逻辑</strong>——做决策时总是使得估计结果更接近目标状态</p><blockquote><p>With heuristics, it becomes very easy to implement logic in our agent that enables them to “prefer” expanding states that are estimated to be closer to goal states when deciding which action to perform. </p></blockquote><p>下面讲到的两种搜索策略都是<strong>基于启发式搜索</strong>的原理。</p><h3 id="Greedy-Search贪婪搜索"><a href="#Greedy-Search贪婪搜索" class="headerlink" title="Greedy Search贪婪搜索"></a>Greedy Search贪婪搜索</h3><ul><li><strong>描述</strong>：贪婪搜索总是选择有<strong>最小启发值（lowest heuristic value）</strong> 的节点来扩展，这些节点对应的是它认为最接近目标的状态。<blockquote><p>Greedy search is a strategy for exploration that always selects the frontier node with the lowest heuristic value for expansion</p></blockquote></li><li><strong>边缘描述</strong>：贪婪搜索的操作和UCS相同，具有优先队列边缘表示。但贪婪搜索的堆中各结点用<strong>估计前进代价（estimated forward cost）</strong> 作为结点权值。<blockquote><p>computed backward cost (the sum of edge weights in the path to the state)</p></blockquote></li><li><strong>完备性与最优性</strong>：对于一个目标状态，贪婪搜索<strong>无法保证能找到它，它也不是最优的</strong>，尤其是在选择了非常糟糕的启发函数的情况下。在不同场景中。它的行为通常是不可预测的，有可能一路直奔目标状态，也有可能像一个被错误引导的DFS一样并遍历所有的错误区域。但注意，贪婪搜索有着<strong>高搜索速度</strong><br><img src="https://notes.sjtu.edu.cn/uploads/upload_34b84739b5f2c63a54923c2858179bc0.png"></li></ul><h3 id="A-search-A-搜索"><a href="#A-search-A-搜索" class="headerlink" title="A* search A*搜索"></a>A* search A*搜索</h3><ul><li><p><strong>描述</strong>：A*搜索总是选择有最低估计总代价（lowest estimated total cost）的边缘节点来扩展</p><blockquote><p>A* search is a strategy for exploration that always selects the frontier node with the lowest estimated total cost for expansion, where total cost is the entire cost from the start node to the goal node.其中lowest estimated total cost是指从起始节点到目标节点的全部代价</p></blockquote></li><li><p><strong>边缘表示</strong>：A*搜索也用一个优先队列来表示它的边缘。但A*搜索使用<strong>估计总代价estimated total value</strong>做结点权值，即<code>估计总代价=估计前进代价+后退代价</code></p></li><li><p><strong>完备性与最优性</strong>：在给定一个<strong>合适的启发函数</strong>（我们很快就能得到）时，A*搜索既是完备的又是最优的，兼备贪婪搜索的高搜索速度以及UCS的完备性和最优性。</p></li></ul><h3 id="Admissibility-and-Consistency-可纳性和一致性"><a href="#Admissibility-and-Consistency-可纳性和一致性" class="headerlink" title="Admissibility and Consistency 可纳性和一致性"></a>Admissibility and Consistency 可纳性和一致性</h3><p>接下来我们来花些时间讨论一下一个好的启发式是由什么构成的。下面定义：</p><ul><li>$g(n)$：UCS的总后退代价函数</li><li>$h(n)$：贪婪搜索的启发值函数，即估计前进代价函数</li><li>$f(n)$：A*搜索使用的估计总代价函数。有$f(n)&#x3D;g(n)+h(n)$</li></ul><p>首先要知道，对于A*搜索，其并不是总是保持其完备与最优。例如，启发函数$h(n)&#x3D;1-g(n)$，则此时$f(n)&#x3D;1$，退化为BFS问题（所有目标结点都在同一层级上），而BFS只有在所有边权值一致时才是最优。因此，使用A*搜索，其最优性有条件，称之为<strong>可纳性admissibility</strong></p><blockquote><p>The admissibility constraint（约束） states（表明） that the value estimated by an admissible heuristic is neither negative（负的） nor an overestimate（过估计）.</p></blockquote><h4 id="可纳性约束"><a href="#可纳性约束" class="headerlink" title="可纳性约束"></a>可纳性约束</h4><p>可纳性约束有数学表示：<br>$\forall{n,0}\leq{h(n)}\leq{h^*(n)}$</p><p><strong>定理</strong>：对于一个给定的搜索问题，如果一个启发式函数h满足可纳性约束，使用含有h的A*树搜索能得到最优解<br><strong>证明</strong>：假设两个可以到达的目标状态，最优目标A和次优目标B在一个给定的搜索问题的搜索树中。因为可以从初始状态到达A，A的某个祖先节点n（有可能是A本身）现在一定在边缘上。用以下三个陈述，我们可以断定n会在B之前被选来扩展</p>]]></content>
    
    
    
    <tags>
      
      <tag>笔记</tag>
      
      <tag>AI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>文章标题</title>
    <link href="/2023/02/06/Basic_AI/"/>
    <url>/2023/02/06/Basic_AI/</url>
    
    <content type="html"><![CDATA[<h1 id="Basical-AI-notes"><a href="#Basical-AI-notes" class="headerlink" title="Basical AI notes"></a>Basical AI notes</h1><h6 id="tags-notes-AI-Basic"><a href="#tags-notes-AI-Basic" class="headerlink" title="tags: notes AI Basic"></a>tags: <code>notes</code> <code>AI</code> <code>Basic</code></h6><p>CS188课程翻译笔记：<br><a href="https://zhuanlan.zhihu.com/p/61895500">知乎|翻译1</a>；<a href="https://zhuanlan.zhihu.com/p/64368643">知乎|翻译2</a>；<a href="https://zhuanlan.zhihu.com/p/148256240">知乎|翻译3</a>；<a href="https://zhuanlan.zhihu.com/p/272652797">知乎|翻译4</a>；原版笔记资料<a href="https://inst.eecs.berkeley.edu/~cs188/sp21/">CS188|Introduction to Artificial Intelligence</a>.<br><img src="https://picx.zhimg.com/80/v2-8b04444c0088fea1efa9778f0dfc2dbb_1440w.webp?source=1940ef5c"></p><h1 id="1-search"><a href="#1-search" class="headerlink" title="1.search"></a>1.search</h1><h2 id="1-1-Agent"><a href="#1-1-Agent" class="headerlink" title="1.1 Agent"></a>1.1 Agent</h2><p>在人工智能中，主要问题是建立一个rational（理性的）的agent，一个<strong>有特定目标或偏好</strong>并会针对这些目标试图<strong>执行一系列操作（action）</strong> 来得到<strong>最优解的实体</strong>（即一个理性<strong>决策者</strong>）环境和agent一起组成了一个<strong>世界</strong></p><h3 id="Reflex-Agent"><a href="#Reflex-Agent" class="headerlink" title="Reflex Agent"></a>Reflex Agent</h3><p><a href="https://en.wikipedia.org/wiki/Intelligent_agent">wiki|intelligent agent</a><br>感知代理(IA).根据当前感知(或者记忆)选择行动<br>可能拥有世界当前状态的记忆或模型<br><strong>不考虑他们行为的未来后果，只是根据世界的当前状态而选择一个操作</strong>；何谓AI，感知其环境，自主采取行动以实现目标，并且可以通过学习或使用知识来提高其性能的任何东西；核心即<strong>目标导向行为视为智能的本质</strong>；<br>其Consider how <strong>the world is</strong></p><h3 id="Planning-Agent"><a href="#Planning-Agent" class="headerlink" title="Planning Agent"></a>Planning Agent</h3><p>有一个世界模型并用这个模型来模拟执行不同的操作，能够确定操作的假想结果并依据此选择最佳操作，即实现<strong>预测</strong><br>Consider how the world <strong>would be</strong><br>have a model of how the world evolves in response to actions；其预测决策、行为的后果</p><hr><h2 id="1-2-State-Spaces-and-Search-Problems-状态空间和搜索问题"><a href="#1-2-State-Spaces-and-Search-Problems-状态空间和搜索问题" class="headerlink" title="1.2 State Spaces and Search Problems 状态空间和搜索问题"></a>1.2 State Spaces and Search Problems 状态空间和搜索问题</h2><h3 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h3><p>首先给出概念定义：</p><ul><li><strong>搜索问题</strong>：给定agent的当前状态（state）（它在环境中的配置），我们如何尽可能最好地达到一个满足目标的新状态</li><li><strong>状态空间state space</strong>：在给定世界中所有可能的状态</li><li><strong>后继函数successor function</strong>：参数包含一个状态和一个操作，并计算执行该操作的<strong>代价</strong>（cost）和执行操作后世界的<strong>后继状态</strong></li><li><strong>起始状态start state</strong>：agent最初存在时当前世界的状态</li><li><strong>目标测试函数goal test</strong>：一个函数，输入一个状态并决定它是否是一个目标状态（是否在<strong>目标集</strong>中）</li><li><strong>世界状态world state</strong>：包含一个给定状态的所有信息</li><li><strong>搜索状态search state</strong>：仅包含对计划（主要是为了空间效率）必要的信息</li></ul><p>示例介绍：本课程使用<strong>吃豆人Pacman游戏</strong>做示例。吃豆人必须探索一个迷宫，吃掉所有的的小豆子并且不被游荡的恶灵吃掉。如果它吃了大豆子，它将在一段时间内无敌并且能吃掉恶灵赚取分</p><p>解决搜索问题的步骤：</p><ol><li>考虑它的起始状态</li><li>用后继函数探索它的状态空间</li><li>反复计算不同状态的后继直到后继为目标状态</li></ol><p>此时建立起<strong>计划路径</strong>连接起始与目标；在解决搜索过程中，由<strong>策略strategy</strong>来决定探索不同状态的顺序。</p><h3 id="世界状态与搜索状态"><a href="#世界状态与搜索状态" class="headerlink" title="世界状态与搜索状态"></a>世界状态与搜索状态</h3><p><em><strong>示例搜索问题</strong></em>迷宫中只有吃豆人和豆子。在这种情况下我们能给出两种不同的搜索问题：路径规划和光盘行动（pathing and eat-all-dots）。路径规划需要找出从位置$(x_1,y_1)$到$(x_2,y_2)$的最佳方案，而光盘行动要求用尽可能短的时间吃掉迷宫中所有的豆子。<img src="https://pic3.zhimg.com/80/v2-0fed5f8a8af2ae536cbe65db806d1dc6_720w.webp"></p><p>路径规划的状态包含的信息比光盘行动要少，因为在光盘行动中我们必须保存一大批布尔值用来表示在给定状态中每个豆子有没有被吃掉。一个世界状态还有可能包含更多的信息，比如吃豆人走过的总距离，或者吃豆人在它的当前位置（x，y）和豆子布尔值上到达过的所有地方这些潜在的编码信息。</p><p>简而言之，世界状态是整个世界中所有的信息，而<strong>搜索状态是对于一个搜索问题其所有需要输入的信息</strong>。</p><h3 id="State-Space-Size-状态空间大小"><a href="#State-Space-Size-状态空间大小" class="headerlink" title="State Space Size 状态空间大小"></a>State Space Size 状态空间大小</h3><p>状态空间大小可以用于<strong>估算搜索问题运行时间</strong>，其唯一计算方法：<br>如果在一个给定的世界里有n个变量分别有$x_1,x_2,x_3…$种不同的取值，那么状态的总数为$x_1x_2x_3x_4…$。</p><p><em><strong>示例</strong></em>：我们用吃豆人来举例说明这个概念，吃豆人有120个位置，前进方向有4个，恶灵有两个，每个恶灵有12个可能位置，共有30个豆子，每个豆子有被吃或未被吃两种状态。则总状态空间大小$120\times4\times12^2\times2^{30}$</p><h3 id="State-Space-Graphs-and-Search-Trees-状态空间图和搜索树"><a href="#State-Space-Graphs-and-Search-Trees-状态空间图和搜索树" class="headerlink" title="State Space Graphs and Search Trees 状态空间图和搜索树"></a>State Space Graphs and Search Trees 状态空间图和搜索树</h3><p>上述示例用了四个部件来完整地定义了一个状态空间。<br><strong>状态空间图（state space graph）</strong> 是由代表状态的结点以及从一个状态指向其后继的有向边构成的。这些边表示操作（action），而任何相关联的权重表示对应操作的代价。每个结点的状态都包括了上述4个元素。<br><strong>注意：</strong> 状态空间图中每个状态只表示一次。</p><p>而对于<strong>搜索树</strong>，其对一个状态的出现次数没有限制。例如，空间图中的极长S → d → e → r → f → G，其在对应搜索树中反映为<strong>从根节点到叶子结点的一个道路</strong>。由于从一个状态到另一个状态通常会有多种方案，搜索树中状态会出现多次。<code>简言之</code>，搜索树中呈现的是搜索路径而不只是结点和结点间关系。<br><img src="https://pic3.zhimg.com/80/v2-4477c7076b96e2ff6609ddcb9e5cfc0e_720w.webp"></p><p>一般在搜索问题中，我们只保存即刻处理的状态，并用相应的后继函数根据需求来计算新的状态。</p><blockquote><p>在树中，我们每次观察那几个非常小心地存储选择的节点，反复地用其后继来替换节点，直到我们到达一个目标状态。</p></blockquote><p>下面将介绍一些方法来决定搜索树中迭代替换结点的顺序（即不同的策略strategy）。</p><h2 id="Uninformed-Search-未知搜索"><a href="#Uninformed-Search-未知搜索" class="headerlink" title="Uninformed Search 未知搜索"></a>Uninformed Search 未知搜索</h2><p>首先介绍<strong>树搜索tree search</strong>：</p><blockquote><p>通过移除一个与部分计划对应的节点（用给定的策略来选择）并用它所有的子节点代替它，我们不断地扩展（expand）我们的边缘(outer fringe)。用子节点代替边缘上的元素,相当于丢弃一个长度为n的计划并考虑所有源于它的长度为（n+1）的计划。我们继续这一操作，直到最终将目标从边缘移除为止。此时我们得出结论，<strong>与移除的目标状态相对应的部分计划其实就是从起始状态到目标状态的一条路径</strong>。</p></blockquote><p>当我们不知道目标状态在搜索树中的的位置时，我们只能从属于<strong>未知搜索（uninformed search）</strong> 的技术中选择用于树搜索的策略。我们将依次介绍<strong>三种策略</strong>：深度优先搜索DFS、广度优先搜索BFS和一致代价搜索UCS，同时包括搜索策略的基本性质，包括完备性、最优性、分支因数h、最大深度m，最浅解深度s</p><h3 id="DFS深度优先搜索"><a href="#DFS深度优先搜索" class="headerlink" title="DFS深度优先搜索"></a>DFS深度优先搜索</h3><p>何为<strong>边缘</strong>，即是当前探索道路的两端（如果不算根的话，即是探索的“头”，多个道路可以有多个头）</p><ul><li><strong>描述</strong>：深度优先搜索DFS总是<strong>选择距离起始节点最深的边缘节点来进行扩展</strong>。DFS选择先访问邻接结点的邻接结点。</li><li><strong>边缘表示</strong>：DFS在边缘将最深结点移除后让最深结点的孩子结点<strong>成为边缘</strong>，此时孩子结点的深度即是<code>原最深结点深度+1</code>。即<strong>边缘中最近添加的对象总有最高优先级</strong>，使用栈（后进先出LIFO）来进行存储。</li><li><strong>完备性</strong>：深度优先搜索<strong>并不具有完备性</strong>。如果在状态空间图中存在回路，这必然意味着相应搜索树的<strong>深度将是无限的</strong>（搜索树是空间图中极长道路组成的，空间图存在回路也就是没有极长道路了）。因此，存在这样一种可能性，即DFS老实地在无限大的搜索树中搜索最深的节点而不幸地陷入僵局，注定无法找到解。</li><li><strong>最优性</strong>：深度优先搜索只是在搜索树中找到“最左边”的解，而没有考虑路径的代价，因此不是最优的。DFS先检索的是邻接表中的第一个邻接结点，<strong>可能有解但不一定是最优解</strong></li><li><strong>时间复杂度</strong>：在最坏情况下，深度优先搜索最终可能会搜遍整个搜索树。</li><li><strong>空间复杂度</strong>：在最坏情况下，DFS在边缘上m个深度级别上都有b个节点。这是一个简单的结果，因为一旦某个父节点的b个子节点进入队列，DFS的本性在任意时间点都只允许研究任意一个子节点的一棵子树。即为$O(bm)$</li></ul><h3 id="BFS广度优先搜索"><a href="#BFS广度优先搜索" class="headerlink" title="BFS广度优先搜索"></a>BFS广度优先搜索</h3><ul><li><strong>描述</strong>：宽度优先搜索总是<strong>选择距离起始节点最浅（近）的边缘节点来扩展</strong>。BFS选择先访问完全所有的邻接结点。</li><li><strong>边缘表示</strong>：如果我们想在较深的节点之前访问较浅的节点，我们必须按照节点的插入顺序来访问它们。使用队列（先进先出FIFO）。</li><li><strong>完备性</strong>：由于总是访问最浅边缘结点，而<strong>最浅结点深度一定是有限的</strong>（在存在解的前提下），故一定可以搜索下去而不会进入死循环，故完备。</li><li><strong>最优性</strong>：BFS一般不是最优的，因为它在选择边缘上被替换的节点时不会考虑代价问题。在所有边的代价都相等的特殊情况下BFS可以保证是最优的，因为这会让BFS退化为一致代价搜索。</li><li><strong>时间复杂度</strong>：遍历所有结点</li><li><strong>空间复杂度</strong>：在最坏情况下，边缘所有节点都在对应最浅解的那一层。（全都要存，都要朝下面找）</li></ul><h3 id="Uniform-Cost-Search-一致代价搜索"><a href="#Uniform-Cost-Search-一致代价搜索" class="headerlink" title="Uniform Cost Search 一致代价搜索"></a>Uniform Cost Search 一致代价搜索</h3><ul><li><strong>描述</strong>：UCS总是选择距离起始节点代价（边权）最小的边缘节点来扩展。</li><li><strong>边缘表示</strong>：UCS的边缘选择用优先堆（<strong>小顶堆</strong>），对于其中的结点v其权重即为从起始节点到v的路径代价，称之为<strong>v的后退代价backward cost</strong>。</li><li><strong>完备性</strong>：如果存在一个目标状态v，它一定有从根到v的有限长度最短路径。故完备</li><li><strong>最优性</strong>：当所有边权非负，UCS是最优的（按照路径代价递增的顺序搜索结点）</li><li><strong>时间复杂度</strong>：<blockquote><p>我们定义最优路径代价为$C^*$，状态空间图内两节点之间最小代价为$\varepsilon$。那么，我们得简单粗暴地遍历深度为从1到$\frac{C^*}{\varepsilon}$范围内的所有节点，导致运行时间为$O\left( b^{\frac{C^*}{\varepsilon}} \right)$。</p></blockquote></li></ul><p>注意：上述三种搜索策略<strong>本质都是树搜索</strong>，只是策略的不同。</p><h2 id="Informed-Search有信息搜索"><a href="#Informed-Search有信息搜索" class="headerlink" title="Informed Search有信息搜索"></a>Informed Search有信息搜索</h2><p>UCS在完备性和最优性上很棒，但时间复杂度较高。如果我们对于我们应该搜索的方向有一定的了解，我们就能显著提高性能并更快地达到目标。这就是有信息搜索。<strong>即已知目标位置，可以估算到目标的距离</strong>。</p><h3 id="Heuristics-启发式搜索"><a href="#Heuristics-启发式搜索" class="headerlink" title="Heuristics 启发式搜索"></a>Heuristics 启发式搜索</h3><p>首先介绍启发式搜索的定义：</p><blockquote><p>Heuristics are the driving force that allow <strong>estimation（估计） of distance to goal states</strong> - they（启发式搜索）’re functions that take in a state as input and output a corresponding estimate. 以一个状态作为输入，以相应的估计为输出。</p></blockquote><p>启发式搜索这种函数是专门用来解决搜索问题的，</p><blockquote><p>we usually want heuristic functions to be a lower bound on this remaining distance to the goal。我们希望启发式搜索可以获得剩余到目标距离的下限，因而启发式搜索通常处理<strong>relaxed problems</strong>。</p></blockquote><p><em><strong>示例</strong></em>：对于前面的路径规划问题，通用解决方法是<strong>曼哈顿距离法Manhattan Distance</strong>。定义两点间曼哈顿距离为：$Manhattan(x_1,y_1,x_2,y_2)&#x3D;|x_1-x_2|+|y_1-y_2|$<br><img src="https://pic4.zhimg.com/80/v2-c3949a1c7834e55745aff852d46447e3_720w.webp" alt="image alt"></p><p>假想要到达左下角，它在计算了<strong>假设没有墙</strong>的情况下从吃豆人现在的位置到目标位置的距离。这个距离是松弛搜索问题中的<strong>精确（exact）距离</strong>，而相应的在实际的搜索问题中计算出的是<strong>估计（estimated）目标距离</strong>。从而实现了为agent<strong>建立“偏好拓展状态”的逻辑</strong>——做决策时总是使得估计结果更接近目标状态</p><blockquote><p>With heuristics, it becomes very easy to implement logic in our agent that enables them to “prefer” expanding states that are estimated to be closer to goal states when deciding which action to perform. </p></blockquote><p>下面讲到的两种搜索策略都是<strong>基于启发式搜索</strong>的原理。</p><h3 id="Greedy-Search贪婪搜索"><a href="#Greedy-Search贪婪搜索" class="headerlink" title="Greedy Search贪婪搜索"></a>Greedy Search贪婪搜索</h3><ul><li><strong>描述</strong>：贪婪搜索总是选择有<strong>最小启发值（lowest heuristic value）</strong> 的节点来扩展，这些节点对应的是它认为最接近目标的状态。<blockquote><p>Greedy search is a strategy for exploration that always selects the frontier node with the lowest heuristic value for expansion</p></blockquote></li><li><strong>边缘描述</strong>：贪婪搜索的操作和UCS相同，具有优先队列边缘表示。但贪婪搜索的堆中各结点用<strong>估计前进代价（estimated forward cost）</strong> 作为结点权值。<blockquote><p>computed backward cost (the sum of edge weights in the path to the state)</p></blockquote></li><li><strong>完备性与最优性</strong>：对于一个目标状态，贪婪搜索<strong>无法保证能找到它，它也不是最优的</strong>，尤其是在选择了非常糟糕的启发函数的情况下。在不同场景中。它的行为通常是不可预测的，有可能一路直奔目标状态，也有可能像一个被错误引导的DFS一样并遍历所有的错误区域。但注意，贪婪搜索有着<strong>高搜索速度</strong><br><img src="https://notes.sjtu.edu.cn/uploads/upload_34b84739b5f2c63a54923c2858179bc0.png"></li></ul><h3 id="A-search-A-搜索"><a href="#A-search-A-搜索" class="headerlink" title="A* search A*搜索"></a>A* search A*搜索</h3><ul><li><p><strong>描述</strong>：A*搜索总是选择有最低估计总代价（lowest estimated total cost）的边缘节点来扩展</p><blockquote><p>A* search is a strategy for exploration that always selects the frontier node with the lowest estimated total cost for expansion, where total cost is the entire cost from the start node to the goal node.其中lowest estimated total cost是指从起始节点到目标节点的全部代价</p></blockquote></li><li><p><strong>边缘表示</strong>：A*搜索也用一个优先队列来表示它的边缘。但A*搜索使用<strong>估计总代价estimated total value</strong>做结点权值，即<code>估计总代价=估计前进代价+后退代价</code></p></li><li><p><strong>完备性与最优性</strong>：在给定一个<strong>合适的启发函数</strong>（我们很快就能得到）时，A*搜索既是完备的又是最优的，兼备贪婪搜索的高搜索速度以及UCS的完备性和最优性。</p></li></ul><h3 id="Admissibility-and-Consistency-可纳性和一致性"><a href="#Admissibility-and-Consistency-可纳性和一致性" class="headerlink" title="Admissibility and Consistency 可纳性和一致性"></a>Admissibility and Consistency 可纳性和一致性</h3><p>接下来我们来花些时间讨论一下一个好的启发式是由什么构成的。下面定义：</p><ul><li>$g(n)$：UCS的总后退代价函数</li><li>$h(n)$：贪婪搜索的启发值函数，即估计前进代价函数</li><li>$f(n)$：A*搜索使用的估计总代价函数。有$f(n)&#x3D;g(n)+h(n)$</li></ul><p>首先要知道，对于A*搜索，其并不是总是保持其完备与最优。例如，启发函数$h(n)&#x3D;1-g(n)$，则此时$f(n)&#x3D;1$，退化为BFS问题（所有目标结点都在同一层级上），而BFS只有在所有边权值一致时才是最优。因此，使用A*搜索，其最优性有条件，称之为<strong>可纳性admissibility</strong></p><blockquote><p>The admissibility constraint（约束） states（表明） that the value estimated by an admissible heuristic is neither negative（负的） nor an overestimate（过估计）.</p></blockquote><h4 id="可纳性约束"><a href="#可纳性约束" class="headerlink" title="可纳性约束"></a>可纳性约束</h4><p>可纳性约束有数学表示：<br>$\forall{n,0}\leq{h(n)}\leq{h^*(n)}$</p><p><strong>定理</strong>：对于一个给定的搜索问题，如果一个启发式函数h满足可纳性约束，使用含有h的A*树搜索能得到最优解<br><strong>证明</strong>：假设两个可以到达的目标状态，最优目标A和次优目标B在一个给定的搜索问题的搜索树中。因为可以从初始状态到达A，A的某个祖先节点n（有可能是A本身）现在一定在边缘上。用以下三个陈述，我们可以断定n会在B之前被选来扩展</p>]]></content>
    
    
    
    <tags>
      
      <tag>笔记</tag>
      
      <tag>AI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2023/02/06/hello-world/"/>
    <url>/2023/02/06/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
