<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>【机器学习】</title>
    <link href="/2023/02/06/machine-learning-notes/"/>
    <url>/2023/02/06/machine-learning-notes/</url>
    
    <content type="html"><![CDATA[<h1 id="machine-learning-notes"><a href="#machine-learning-notes" class="headerlink" title="machine learning notes"></a>machine learning notes</h1><h6 id="tags-notes-machine-learning"><a href="#tags-notes-machine-learning" class="headerlink" title="tags: notes machine learning"></a>tags: <code>notes</code> <code>machine learning</code></h6><p><strong>github的上传</strong>，见链接<a href="https://blog.csdn.net/oxofcarrot/article/details/104051984">CSDN|github上传</a>与<a href="https://zhuanlan.zhihu.com/p/112884264">知乎|github仓库更新</a>，<a href="https://www.jianshu.com/p/4925b267f0fd">git提交代码流程</a></p><p>本学习笔记源代码见github链接<a href="https://github.com/mhjiang0408/machine_learning.git">github|源代码项目仓库</a></p><h2 id="1-kNN分类算法"><a href="#1-kNN分类算法" class="headerlink" title="1.kNN分类算法"></a>1.kNN分类算法</h2><p>kNN算法，是在<strong>已知各训练数据元类型下</strong>，<strong>基于欧式距离计算</strong>，计算待预测点与什么类距离最近。</p><h3 id="1-1-numpy补充"><a href="#1-1-numpy补充" class="headerlink" title="1.1 numpy补充"></a>1.1 numpy补充</h3><p>学习链接<a href="https://www.cjavapy.com/article/902/">numpy学习网站1</a><br><a href="http://www.learnfk.com/numpy/numpy-argsort.html">numpy学习网站2</a></p><h4 id="对shape"><a href="#对shape" class="headerlink" title="对shape"></a>对shape</h4><p>有例子<br><strong>核心：0为行轴，shape[0]为有多少行</strong><br>一维：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>x1 = np.array([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>])<br>y1 = np.array([[<span class="hljs-number">1</span>],[<span class="hljs-number">2</span>]])<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;x1:\n&quot;</span>,x1)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;y1:\n&quot;</span>,y1)<br>      <br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;x1.shape:\n&quot;</span>,x1.shape)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;y1.shape:\n&quot;</span>,y1.shape)<br>&gt;&gt;&gt;<br>x1:<br> [<span class="hljs-number">1</span> <span class="hljs-number">2</span>]<br>y1:<br> [[<span class="hljs-number">1</span>]<br> [<span class="hljs-number">2</span>]]<br>x1.shape:<br> (<span class="hljs-number">2</span>,)<br>y1.shape:<br> (<span class="hljs-number">2</span>, <span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><p> 二维：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python">y2 = np.array([[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>],[<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>]])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;y2:\n&quot;</span>,y2)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;y2.shape:\n&quot;</span>,y2.shape)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;y2.shape[0]:\n&quot;</span>,y2.shape[<span class="hljs-number">0</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;y2.shape[1]:\n&quot;</span>,y2.shape[<span class="hljs-number">1</span>])<br>&gt;&gt;&gt;<br>y2:<br> [[<span class="hljs-number">1</span> <span class="hljs-number">2</span> <span class="hljs-number">3</span>]<br> [<span class="hljs-number">4</span> <span class="hljs-number">5</span> <span class="hljs-number">6</span>]]<br>y2.shape:<br> (<span class="hljs-number">2</span>, <span class="hljs-number">3</span>)<br>y2.shape[<span class="hljs-number">0</span>]:<br> <span class="hljs-number">2</span><br>y2.shape[<span class="hljs-number">1</span>]:<br> <span class="hljs-number">3</span><br></code></pre></td></tr></table></figure><p> 三维：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"> y3  = np.array([[[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>],[<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>]],[[<span class="hljs-number">7</span>,<span class="hljs-number">8</span>,<span class="hljs-number">9</span>],[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>]],[[<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>],[<span class="hljs-number">6</span>,<span class="hljs-number">7</span>,<span class="hljs-number">8</span>]]])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;y3:\n&quot;</span>,y3)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;y3.shape:\n&quot;</span>,y3.shape)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;y3.shape[0]:\n&quot;</span>,y3.shape[<span class="hljs-number">0</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;y3.shape[1]:\n&quot;</span>,y3.shape[<span class="hljs-number">1</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;y3.shape[2]:\n&quot;</span>,y3.shape[<span class="hljs-number">2</span>])<br>&gt;&gt;&gt;<br>y3:<br> [[[<span class="hljs-number">1</span> <span class="hljs-number">2</span> <span class="hljs-number">3</span>]<br>  [<span class="hljs-number">4</span> <span class="hljs-number">5</span> <span class="hljs-number">6</span>]]<br><br> [[<span class="hljs-number">7</span> <span class="hljs-number">8</span> <span class="hljs-number">9</span>]<br>  [<span class="hljs-number">0</span> <span class="hljs-number">1</span> <span class="hljs-number">2</span>]]<br><br> [[<span class="hljs-number">3</span> <span class="hljs-number">4</span> <span class="hljs-number">5</span>]<br>  [<span class="hljs-number">6</span> <span class="hljs-number">7</span> <span class="hljs-number">8</span>]]]<br>y3.shape:<br> (<span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>)<br>y3.shape[<span class="hljs-number">0</span>]:<br> <span class="hljs-number">3</span><br>y3.shape[<span class="hljs-number">1</span>]:<br> <span class="hljs-number">2</span><br>y3.shape[<span class="hljs-number">2</span>]:<br> <span class="hljs-number">3</span><br></code></pre></td></tr></table></figure><p> 其中，x.shape[0]代表包含二维数组的个数，x.shape[1]表示二维数组的行数，x.shape[2]表示二维数组的列数</p><h4 id="对于乘法"><a href="#对于乘法" class="headerlink" title="对于乘法"></a>对于乘法</h4><p> 有学习链接<a href="https://zhuanlan.zhihu.com/p/334562951">numpy乘法学习</a><br> 所谓<strong>数组星乘</strong>，就是数组的对应元素相乘，这也是初学NumPy的同学最早接触到的数组乘法。即使两个数组的shape不一样，只要满足特定条件，同样可以用星号相乘，且满足交换律。</p><p> 对于<strong>一维数组</strong>，NumPy的点乘就是向量点乘，其结果是一个标量。对于多维数组，则需要满足一定条件才能实现点乘，且其结果不再是标量，而是一个多维数组。比如，NumPy的矩阵相乘，就是二维数组的点乘，参与点乘的第一个数组的列数必须等于第二个数组的行数。</p><p> 在数学上，二维平面的向量叉乘，其结果是以两个向量为边的菱形的面积，三维空间的向量叉乘，其结果是仍然是一个向量，且垂直于相乘的两个向量，也就是参与相乘的两个向量决定的平面的法向量。nunpy.cross()函数可以实现<strong>向量（一维数组）叉乘</strong>，也可以实现<strong>二维或三维数组的叉乘</strong>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"> &gt;&gt;&gt; a = np.array([<span class="hljs-number">2</span>,<span class="hljs-number">0</span>])<br><span class="hljs-meta">&gt;&gt;&gt; </span>b = np.array([<span class="hljs-number">2</span>,<span class="hljs-number">2</span>])<br><span class="hljs-meta">&gt;&gt;&gt; </span>np.cross(a,b) <span class="hljs-comment"># 平面向量叉乘，其结果是以两个向量为边的菱形的面积</span><br>array(<span class="hljs-number">4</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>a = np.array([<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>])<br><span class="hljs-meta">&gt;&gt;&gt; </span>b = np.array([<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>])<br><span class="hljs-meta">&gt;&gt;&gt; </span>np.cross(a,b) <span class="hljs-comment"># x轴叉乘y轴，得到z轴</span><br>array([<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>])<br><span class="hljs-meta">&gt;&gt;&gt; </span>np.cross(b,a) <span class="hljs-comment"># 叉乘交换顺序，得到反向的法向量</span><br>array([ <span class="hljs-number">0</span>,  <span class="hljs-number">0</span>, -<span class="hljs-number">1</span>])<br></code></pre></td></tr></table></figure><p>这里的<strong>外乘</strong>，类似于星乘，并不是通用的概念，也是我自己编造的一个说法，来源于numpy.outer()函数。从字面看，outer()函数更像是求外积，但从实际效果看，更像是笛卡尔直积，因此我这里用了“外乘”而不是“外积”。那么，outer()函数究竟能作什么呢？<br>数组A外乘数组B，返回一个二维数组，这个二维数组的第i行是数组A的第i个元素星乘数组B。</p><p><code>**</code>为<strong>乘方</strong>，如<code>a**2=a^2</code></p><p>对<strong>排序argsort</strong>，其返回的是各个排序的index，如b[0]上是最小元素的index，有示例</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>a=np.array([<span class="hljs-number">456</span>,<span class="hljs-number">11</span>,<span class="hljs-number">63</span>])<br>a<br>b=np.argsort(a)<br>b<br>output:<br>array([<span class="hljs-number">456</span>,  <span class="hljs-number">11</span>,  <span class="hljs-number">63</span>])<br>array([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>], dtype=int64)<br></code></pre></td></tr></table></figure><p>对<strong>列表排序函数sorted</strong>，<code>sorted(iterable[, cmp[, key[, reverse]]]) </code><br>cmp是比较的函数，这个具有两个参数，参数的值都是从可迭代对象中取出，此函数必须遵守的规则为，大于则返回1，小于则返回-1，等于则返回0<br>有示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python">&gt;&gt;&gt;a = [<span class="hljs-number">5</span>,<span class="hljs-number">7</span>,<span class="hljs-number">6</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>]<br><span class="hljs-meta">&gt;&gt;&gt; </span>b = <span class="hljs-built_in">sorted</span>(a) <span class="hljs-comment"># 保留原列表</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>a<br>[<span class="hljs-number">5</span>, <span class="hljs-number">7</span>, <span class="hljs-number">6</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>]<br><span class="hljs-meta">&gt;&gt;&gt; </span>b<br>[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>]<br><span class="hljs-meta">&gt;&gt;&gt; </span>L=[(<span class="hljs-string">&#x27;b&#x27;</span>,<span class="hljs-number">2</span>),(<span class="hljs-string">&#x27;a&#x27;</span>,<span class="hljs-number">1</span>),(<span class="hljs-string">&#x27;c&#x27;</span>,<span class="hljs-number">3</span>),(<span class="hljs-string">&#x27;d&#x27;</span>,<span class="hljs-number">4</span>)]<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">sorted</span>(L, cmp=<span class="hljs-keyword">lambda</span> x,y:cmp(x[<span class="hljs-number">1</span>],y[<span class="hljs-number">1</span>])) <span class="hljs-comment"># 利⽤cmp函数</span><br>[(<span class="hljs-string">&#x27;a&#x27;</span>, <span class="hljs-number">1</span>), (<span class="hljs-string">&#x27;b&#x27;</span>, <span class="hljs-number">2</span>), (<span class="hljs-string">&#x27;c&#x27;</span>, <span class="hljs-number">3</span>), (<span class="hljs-string">&#x27;d&#x27;</span>, <span class="hljs-number">4</span>)]<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">sorted</span>(L, key=<span class="hljs-keyword">lambda</span> x:x[<span class="hljs-number">1</span>]) <span class="hljs-comment"># 利⽤key</span><br>[(<span class="hljs-string">&#x27;a&#x27;</span>, <span class="hljs-number">1</span>), (<span class="hljs-string">&#x27;b&#x27;</span>, <span class="hljs-number">2</span>), (<span class="hljs-string">&#x27;c&#x27;</span>, <span class="hljs-number">3</span>), (<span class="hljs-string">&#x27;d&#x27;</span>, <span class="hljs-number">4</span>)]<br><span class="hljs-meta">&gt;&gt;&gt; </span>students = [(<span class="hljs-string">&#x27;john&#x27;</span>, <span class="hljs-string">&#x27;A&#x27;</span>, <span class="hljs-number">15</span>), (<span class="hljs-string">&#x27;jane&#x27;</span>, <span class="hljs-string">&#x27;B&#x27;</span>, <span class="hljs-number">12</span>), (<span class="hljs-string">&#x27;dave&#x27;</span>, <span class="hljs-string">&#x27;B&#x27;</span>, <span class="hljs-number">10</span>)]<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">sorted</span>(students, key=<span class="hljs-keyword">lambda</span> s: s[<span class="hljs-number">2</span>]) <span class="hljs-comment"># 按年龄排序</span><br>[(<span class="hljs-string">&#x27;dave&#x27;</span>, <span class="hljs-string">&#x27;B&#x27;</span>, <span class="hljs-number">10</span>), (<span class="hljs-string">&#x27;jane&#x27;</span>, <span class="hljs-string">&#x27;B&#x27;</span>, <span class="hljs-number">12</span>), (<span class="hljs-string">&#x27;john&#x27;</span>, <span class="hljs-string">&#x27;A&#x27;</span>, <span class="hljs-number">15</span>)]<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">sorted</span>(students, key=<span class="hljs-keyword">lambda</span> s: s[<span class="hljs-number">2</span>], reverse=<span class="hljs-literal">True</span>) <span class="hljs-comment"># 按降序</span><br>[(<span class="hljs-string">&#x27;john&#x27;</span>, <span class="hljs-string">&#x27;A&#x27;</span>, <span class="hljs-number">15</span>), (<span class="hljs-string">&#x27;jane&#x27;</span>, <span class="hljs-string">&#x27;B&#x27;</span>, <span class="hljs-number">12</span>), (<span class="hljs-string">&#x27;dave&#x27;</span>, <span class="hljs-string">&#x27;B&#x27;</span>, <span class="hljs-number">10</span>)]<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">sorted</span>(student_tuples, key = itemgetter(<span class="hljs-number">2</span>))  <span class="hljs-comment"># 根据年龄排序</span><br>[(<span class="hljs-string">&#x27;dave&#x27;</span>, <span class="hljs-string">&#x27;B&#x27;</span>, <span class="hljs-number">10</span>), (<span class="hljs-string">&#x27;jane&#x27;</span>, <span class="hljs-string">&#x27;B&#x27;</span>, <span class="hljs-number">12</span>), (<span class="hljs-string">&#x27;john&#x27;</span>, <span class="hljs-string">&#x27;A&#x27;</span>, <span class="hljs-number">15</span>)]<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">sorted</span>(student_tuples, key = itemgetter(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>))  <span class="hljs-comment"># 根据成绩和年龄排序</span><br>[(<span class="hljs-string">&#x27;john&#x27;</span>, <span class="hljs-string">&#x27;A&#x27;</span>, <span class="hljs-number">15</span>), (<span class="hljs-string">&#x27;dave&#x27;</span>, <span class="hljs-string">&#x27;B&#x27;</span>, <span class="hljs-number">10</span>), (<span class="hljs-string">&#x27;jane&#x27;</span>, <span class="hljs-string">&#x27;B&#x27;</span>, <span class="hljs-number">12</span>)]<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">sorted</span>(student_tuples, key = itemgetter(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>), reverse=<span class="hljs-literal">True</span>) <span class="hljs-comment"># 反转排序结果</span><br>[(<span class="hljs-string">&#x27;jane&#x27;</span>, <span class="hljs-string">&#x27;B&#x27;</span>, <span class="hljs-number">12</span>), (<span class="hljs-string">&#x27;dave&#x27;</span>, <span class="hljs-string">&#x27;B&#x27;</span>, <span class="hljs-number">10</span>), (<span class="hljs-string">&#x27;john&#x27;</span>, <span class="hljs-string">&#x27;A&#x27;</span>, <span class="hljs-number">15</span>)]<br></code></pre></td></tr></table></figure><p>对于operator中的<code>itemgetter</code>函数，是返回一个函数；sorted使用的时候，相当于对于每个“行”都用<code>itemgetter</code>获取了他的关键元（可以是一个，也可以是多个组成的元组）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">a = [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>] <br><span class="hljs-meta">&gt;&gt;&gt; </span>b=operator.itemgetter(<span class="hljs-number">1</span>)      //定义函数b，获取对象的第<span class="hljs-number">1</span>个域的值<br><span class="hljs-meta">&gt;&gt;&gt; </span>b(a) <br><span class="hljs-number">2</span> <br><span class="hljs-meta">&gt;&gt;&gt; </span>b=operator.itemgetter(<span class="hljs-number">1</span>,<span class="hljs-number">0</span>)   //定义函数b，获取对象的第<span class="hljs-number">1</span>个域和第<span class="hljs-number">0</span>个的值<br><span class="hljs-meta">&gt;&gt;&gt; </span>b(a) <br>(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>) <br></code></pre></td></tr></table></figure><h3 id="1-2-matplotlib补充"><a href="#1-2-matplotlib补充" class="headerlink" title="1.2 matplotlib补充"></a>1.2 matplotlib补充</h3><p>matplotlib绘图基础教程见<a href="https://zhuanlan.zhihu.com/p/147644694">知乎|Matplotlib绘图</a><br>matplotlib的绘图函数库<strong>pyplot</strong>有示例如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-comment"># 添加3行3列子图中的第1个子图，并将其为当前子图</span><br>plt.subplot(<span class="hljs-number">331</span>)<br>plt.bar(<span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-number">4</span>),<span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-number">4</span>))<br><span class="hljs-comment"># 添加3行3列子图中的第5个子图，并将其为当前子图</span><br>plt.subplot(<span class="hljs-number">335</span>)<br>plt.pie([<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>])<br><span class="hljs-comment"># 添加3行3列子图中的第9个子图，并将其为当前子图</span><br><span class="hljs-comment"># 返回值为Axes对象</span><br>ax=plt.subplot(<span class="hljs-number">339</span>)<br><span class="hljs-comment"># 使用Axes的方法（面向对象模式）绘制点</span><br>ax.plot([<span class="hljs-number">1</span>],<span class="hljs-string">&#x27;o&#x27;</span>)<br><br>plt.show()<br></code></pre></td></tr></table></figure><p><strong>散点图绘制</strong>scatter函数，相关链接<a href="https://blog.csdn.net/mighty13/article/details/114193446">CSDN|scatter</a> <code>matplotlib.pyplot.scatter(x, y, s=None, c=None, marker=None, cmap=None, norm=None, vmin=None, vmax=None, alpha=None, linewidths=None, verts=None, edgecolors=None, *, data=None, **kwargs)</code><br>基本用法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> random<br><br><span class="hljs-comment"># 0.准备数据</span><br>x = <span class="hljs-built_in">range</span>(<span class="hljs-number">60</span>)<br>y_jiangsu = [random.uniform(<span class="hljs-number">15</span>, <span class="hljs-number">25</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> x]<br>y_beijing = [random.uniform(<span class="hljs-number">5</span>,<span class="hljs-number">18</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> x]<br><br><span class="hljs-comment"># 1.创建画布</span><br>plt.figure(figsize=(<span class="hljs-number">20</span>, <span class="hljs-number">8</span>), dpi=<span class="hljs-number">100</span>)<br><br><span class="hljs-comment"># 2.绘制图像</span><br>plt.scatter(x,y_jiangsu, s=<span class="hljs-number">100</span>, c=<span class="hljs-string">&#x27;deeppink&#x27;</span>, marker=<span class="hljs-string">&#x27;o&#x27;</span>, label = <span class="hljs-string">&quot;江苏&quot;</span>)<br>plt.scatter(x,y_beijing, s=<span class="hljs-number">100</span>, c=<span class="hljs-string">&#x27;darkblue&#x27;</span>, marker=<span class="hljs-string">&#x27;+&#x27;</span>, label = <span class="hljs-string">&quot;北京&quot;</span>)<br><br><span class="hljs-comment"># 2.1 刻度显示</span><br>plt.xticks(x[::<span class="hljs-number">5</span>], x_ticks_label[::<span class="hljs-number">5</span>])<br>plt.yticks(y_ticks[::<span class="hljs-number">5</span>])<br><br><span class="hljs-comment"># 2.2 添加网格显示</span><br>plt.grid(<span class="hljs-literal">True</span>, linestyle=<span class="hljs-string">&quot;--&quot;</span>, alpha=<span class="hljs-number">0.5</span>)<br><br><span class="hljs-comment"># 2.3 添加描述信息</span><br>plt.xlabel(<span class="hljs-string">&quot;时间&quot;</span>, fontsize=<span class="hljs-number">15</span>)<br>plt.ylabel(<span class="hljs-string">&quot;温度&quot;</span>, fontsize=<span class="hljs-number">15</span>)<br>plt.title(<span class="hljs-string">&quot;中午11点--12点某城市温度变化图&quot;</span>, fontsize=<span class="hljs-number">20</span>)<br><br><span class="hljs-comment"># 2.4 图像保存</span><br>plt.savefig(<span class="hljs-string">&quot;./test.png&quot;</span>)<br><br><span class="hljs-comment"># 2.5 添加图例</span><br>plt.legend(loc=<span class="hljs-string">&quot;best&quot;</span>)<br><br><span class="hljs-comment"># 3.图像显示</span><br>plt.show()<br></code></pre></td></tr></table></figure><h3 id="1-3-tile"><a href="#1-3-tile" class="headerlink" title="1.3 tile"></a>1.3 tile</h3><p><code>tile(inX,(m,n))</code>对inX，横向重复n次，竖向重复m次</p><h2 id="2-决策树算法"><a href="#2-决策树算法" class="headerlink" title="2.决策树算法"></a>2.决策树算法</h2><p>本次采用<strong>ID3</strong>算法来划分数据集，具体算法可见链接<a href="https://en.wikipedia.org/wiki/ID3_algorithm">wiki|ID3_algorithm</a>。</p><p>注意：决策树算法是<strong>已知各数据元是什么类型</strong>，只是给出类型<strong>划分的依据</strong>。对于每个<strong>数据元</strong>，可以有很多特征（一个数据元是一行，是一条记录），但每次划分数据集的时候，只会使用一个参考特征。</p><h3 id="2-1-信息增益"><a href="#2-1-信息增益" class="headerlink" title="2.1 信息增益"></a>2.1 信息增益</h3><p>划分数据的依据就是信息增益，即将无序的数据变有序——使用信息论度量信息。<br><strong>定义1</strong>：符号$x_i$的<strong>信息</strong>$l(x_i)&#x3D;-log_2p(x_i)$，其中$p(x_i)$为选择该分类的概率<br><strong>定义2</strong>：<strong>熵</strong>为所有类别选择的信息期望值，$H&#x3D;-\sum_{i&#x3D;1}^n{p\left( x_i \right) \log _2p\left( x_i \right)}$</p><p>对于数据集，其$p(x_i)$为<code>probOfKey = float(numOfTheKey)/(len(dataSet))</code><br>对于每种划分方式，其信息熵为以每个值为划分值划出的数目来算概率，再乘上该划分值划出的dataSet的信息熵，即：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> value <span class="hljs-keyword">in</span> uniqueVals:<br>    <span class="hljs-comment"># 对于一个特征的每个数值，都要以他为划分值算一下划分结果与信息熵</span><br>    subDataSet = splitDataSet(dataSet,i,value)<br>    <span class="hljs-comment"># 算熵(概率就是被筛出来的概率)</span><br>    prob = <span class="hljs-built_in">len</span>(subDataSet)/<span class="hljs-built_in">float</span>(<span class="hljs-built_in">len</span>(dataSet))<br>    newEntopy += prob* calcShannonEnt(subDataSet)<br></code></pre></td></tr></table></figure><p>补充，<code>字典.keys()</code>可以遍历字典的所有key值，<code>if currentLabel not in labelCounts.keys(): </code></p><p>当熵越大，说明混合的数据越多。</p><h4 id="划分数据集"><a href="#划分数据集" class="headerlink" title="划分数据集"></a>划分数据集</h4><p>对每个特征划分数据集的结果计算一次信息熵，比较得按照哪个特征划分数据集是最好的划分方式。</p><p><strong>注意！</strong> 在选择用哪个特征时，每个特征对应的信息增益等于<strong>原始熵-该特征对应信息熵</strong>。而对于该特征对应的信息熵，每个概率就是在每个值下筛出去的概率，每个值对应的<strong>信息就是在该值下筛出来的数据集的信息熵</strong>。</p><p>对于数组的扩充，要将一个列表的各个元素扩充进来，则用<code>extend</code>，而对于<code>append</code>，是列表扩充为被扩充列表的一个元素。如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">a = [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-string">&#x27;3&#x27;</span>]<br>a.append(b)<br>b = [<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-string">&#x27;6&#x27;</span>]<br>c = [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-string">&#x27;3&#x27;</span>]<br>c.extend(b)<br><span class="hljs-meta">&gt;&gt;&gt; </span>a<br>[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-string">&#x27;3&#x27;</span>, [<span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-string">&#x27;6&#x27;</span>]]<br><span class="hljs-meta">&gt;&gt;&gt; </span>c<br>[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-string">&#x27;3&#x27;</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-string">&#x27;6&#x27;</span>] <br></code></pre></td></tr></table></figure><p>补充：<code>set</code>，集合函数，是python的内置函数，接收一个list为参数，创建一个无序不重复元素集，可进行关系测试，删除重复数据，还可以计算交集、差集、并集等。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">list1=[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>]<br>s=<span class="hljs-built_in">set</span>(list1)<br><span class="hljs-built_in">print</span>(s)<br>s.add(<span class="hljs-number">4</span>)<br>s.add(<span class="hljs-number">5</span>)<br>s.remove(<span class="hljs-string">&#x27;zhang&#x27;</span>)<br><span class="hljs-built_in">print</span>(s)<br><span class="hljs-comment">#交集，使用&amp;操作符</span><br>s3=s1&amp;s2<br><span class="hljs-comment">#并集，使用|操作符</span><br>s4=s1|s2<br>输出：<br><span class="hljs-built_in">set</span>([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>])<br><span class="hljs-built_in">set</span>([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>])<br></code></pre></td></tr></table></figure><h3 id="2-2-递归构建决策树"><a href="#2-2-递归构建决策树" class="headerlink" title="2.2 递归构建决策树"></a>2.2 递归构建决策树</h3><p><strong>递归结束</strong>（即构建出叶子结点）的条件是在该结点下的分支所有实例都有相同的分类；若数据集已经处理了所有属性，但还是有分支类别标签<strong>不唯一</strong>，则使用<strong>多数表决</strong>的方法来确定该叶子结点的分类。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">creatTree</span>(<span class="hljs-params">dataSet,labels</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;递归创建树</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        dataSet (_type_matrix): 数据集</span><br><span class="hljs-string">        labels (_type_list): 所有特征的标签</span><br><span class="hljs-string">    return:创建出的树，myTree[a][b]，a是对应的结点，b是节点下对应的分支的值</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    classList = [example[-<span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> example <span class="hljs-keyword">in</span> dataSet]<br>    <span class="hljs-keyword">if</span> classList.count(classList[<span class="hljs-number">0</span>]) == <span class="hljs-built_in">len</span>(classList):<br>        <span class="hljs-comment"># 若跟第一个相同的元素个数与总数目一致，则说明类别完全相同，可以退出</span><br>        <span class="hljs-keyword">return</span> classList[<span class="hljs-number">0</span>] <span class="hljs-comment"># 返回结点类别标签</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(dataSet[<span class="hljs-number">0</span>])==<span class="hljs-number">1</span>:<br>        <span class="hljs-comment"># 当遍历完了所有特征还没出来，就返回次数最多的类别</span><br>        <span class="hljs-keyword">return</span> majorityCnt(classList)<br>    <span class="hljs-comment"># 若要选，选出最佳并建立树</span><br>    bestFeat = chooseFeatureToSplit(dataSet)<br>    bestFeatLabel = labels[bestFeat]<br>    myTree = &#123;bestFeatLabel:&#123;&#125;&#125;<br>    <span class="hljs-keyword">del</span>(labels[bestFeat])   <span class="hljs-comment"># 删除元素</span><br>    featValues = [example[bestFeat] <span class="hljs-keyword">for</span> example <span class="hljs-keyword">in</span> dataSet]<br>    uniqueVals = <span class="hljs-built_in">set</span>(featValues)<br>    <span class="hljs-keyword">for</span> value <span class="hljs-keyword">in</span> uniqueVals:<br>        subLabels = labels[:]<br>        <span class="hljs-comment"># myTree[a][b]，a是对应的结点，b是节点下对应的分支的值</span><br>        myTree[bestFeatLabel][value] = creatTree(splitDataSet(dataSet,bestFeat,value),subLabels)<br>        <span class="hljs-comment"># 这里就解释了，为什么上面特征数的统计用dataSet[0]；每次向下一级递归函数传的是splitDataSet，</span><br>    <span class="hljs-keyword">return</span> myTree<br></code></pre></td></tr></table></figure><h4 id="递归思路"><a href="#递归思路" class="headerlink" title="递归思路"></a>递归思路</h4><p>如果<strong>不是出口</strong>，creatTree返回的是一个树（即一个value是字典的字典），<strong>这个树挂载在上一级结点上</strong>，即挂在myTree[feat][value]；因此，要访问叶子结点，就是<code>myTree[feat1][feat1Value1][feat2][feat2Value2][feat3][feat3Value3]...[featNValueN]</code></p><p>如果<strong>是出口</strong>，creatTree返回的是一个列表，也就是使得上一节点依value下来的分支为一个列表，程序结束，回溯。</p><h3 id="2-3-绘制树形图"><a href="#2-3-绘制树形图" class="headerlink" title="2.3 绘制树形图"></a>2.3 绘制树形图</h3><p>matplotlib中的<code>ax1</code>是来自于子图，是通过在画布<code>fig</code>中<strong>添加子图</strong><code>ax1=fig.add_subplot</code>，进而在子图上绘制曲线。</p><h2 id="补充：Anaconda和Pycharm的安装与配置"><a href="#补充：Anaconda和Pycharm的安装与配置" class="headerlink" title="补充：Anaconda和Pycharm的安装与配置"></a>补充：Anaconda和Pycharm的安装与配置</h2><p>参考教学链接<a href="https://www.cnblogs.com/yuxuefeng/articles/9235431.html">cnblogs|Anaconda和Pycharm的安装和配置</a></p>]]></content>
    
    
    <categories>
      
      <category>笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>笔记</tag>
      
      <tag>机器学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【AU3323】人工智能基础笔记</title>
    <link href="/2023/02/06/basicAI/"/>
    <url>/2023/02/06/basicAI/</url>
    
    <content type="html"><![CDATA[<h1 id="Basical-AI-notes"><a href="#Basical-AI-notes" class="headerlink" title="Basical AI notes"></a>Basical AI notes</h1><h6 id="tags-notes-AI-Basic"><a href="#tags-notes-AI-Basic" class="headerlink" title="tags: notes AI Basic"></a>tags: <code>notes</code> <code>AI</code> <code>Basic</code></h6><p>CS188课程翻译笔记：<br><a href="https://zhuanlan.zhihu.com/p/61895500">知乎|翻译1</a>；<a href="https://zhuanlan.zhihu.com/p/64368643">知乎|翻译2</a>；<a href="https://zhuanlan.zhihu.com/p/148256240">知乎|翻译3</a>；<a href="https://zhuanlan.zhihu.com/p/272652797">知乎|翻译4</a>；原版笔记资料<a href="https://inst.eecs.berkeley.edu/~cs188/sp21/">CS188|Introduction to Artificial Intelligence</a>.<br><img src="https://picx.zhimg.com/80/v2-8b04444c0088fea1efa9778f0dfc2dbb_1440w.webp?source=1940ef5c"></p><h1 id="1-search"><a href="#1-search" class="headerlink" title="1.search"></a>1.search</h1><h2 id="1-1-Agent"><a href="#1-1-Agent" class="headerlink" title="1.1 Agent"></a>1.1 Agent</h2><p>在人工智能中，主要问题是建立一个rational（理性的）的agent，一个<strong>有特定目标或偏好</strong>并会针对这些目标试图<strong>执行一系列操作（action）</strong> 来得到<strong>最优解的实体</strong>（即一个理性<strong>决策者</strong>）环境和agent一起组成了一个<strong>世界</strong></p><h3 id="Reflex-Agent"><a href="#Reflex-Agent" class="headerlink" title="Reflex Agent"></a>Reflex Agent</h3><p><a href="https://en.wikipedia.org/wiki/Intelligent_agent">wiki|intelligent agent</a><br>感知代理(IA).根据当前感知(或者记忆)选择行动<br>可能拥有世界当前状态的记忆或模型<br><strong>不考虑他们行为的未来后果，只是根据世界的当前状态而选择一个操作</strong>；何谓AI，感知其环境，自主采取行动以实现目标，并且可以通过学习或使用知识来提高其性能的任何东西；核心即<strong>目标导向行为视为智能的本质</strong>；<br>其Consider how <strong>the world is</strong></p><h3 id="Planning-Agent"><a href="#Planning-Agent" class="headerlink" title="Planning Agent"></a>Planning Agent</h3><p>有一个世界模型并用这个模型来模拟执行不同的操作，能够确定操作的假想结果并依据此选择最佳操作，即实现<strong>预测</strong><br>Consider how the world <strong>would be</strong><br>have a model of how the world evolves in response to actions；其预测决策、行为的后果</p><hr><h2 id="1-2-State-Spaces-and-Search-Problems-状态空间和搜索问题"><a href="#1-2-State-Spaces-and-Search-Problems-状态空间和搜索问题" class="headerlink" title="1.2 State Spaces and Search Problems 状态空间和搜索问题"></a>1.2 State Spaces and Search Problems 状态空间和搜索问题</h2><h3 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h3><p>首先给出概念定义：</p><ul><li><strong>搜索问题</strong>：给定agent的当前状态（state）（它在环境中的配置），我们如何尽可能最好地达到一个满足目标的新状态</li><li><strong>状态空间state space</strong>：在给定世界中所有可能的状态</li><li><strong>后继函数successor function</strong>：参数包含一个状态和一个操作，并计算执行该操作的<strong>代价</strong>（cost）和执行操作后世界的<strong>后继状态</strong></li><li><strong>起始状态start state</strong>：agent最初存在时当前世界的状态</li><li><strong>目标测试函数goal test</strong>：一个函数，输入一个状态并决定它是否是一个目标状态（是否在<strong>目标集</strong>中）</li><li><strong>世界状态world state</strong>：包含一个给定状态的所有信息</li><li><strong>搜索状态search state</strong>：仅包含对计划（主要是为了空间效率）必要的信息</li></ul><p>示例介绍：本课程使用<strong>吃豆人Pacman游戏</strong>做示例。吃豆人必须探索一个迷宫，吃掉所有的的小豆子并且不被游荡的恶灵吃掉。如果它吃了大豆子，它将在一段时间内无敌并且能吃掉恶灵赚取分</p><p>解决搜索问题的步骤：</p><ol><li>考虑它的起始状态</li><li>用后继函数探索它的状态空间</li><li>反复计算不同状态的后继直到后继为目标状态</li></ol><p>此时建立起<strong>计划路径</strong>连接起始与目标；在解决搜索过程中，由<strong>策略strategy</strong>来决定探索不同状态的顺序。</p><h3 id="世界状态与搜索状态"><a href="#世界状态与搜索状态" class="headerlink" title="世界状态与搜索状态"></a>世界状态与搜索状态</h3><p><em><strong>示例搜索问题</strong></em>迷宫中只有吃豆人和豆子。在这种情况下我们能给出两种不同的搜索问题：路径规划和光盘行动（pathing and eat-all-dots）。路径规划需要找出从位置$(x_1,y_1)$到$(x_2,y_2)$的最佳方案，而光盘行动要求用尽可能短的时间吃掉迷宫中所有的豆子。<img src="https://pic3.zhimg.com/80/v2-0fed5f8a8af2ae536cbe65db806d1dc6_720w.webp"></p><p>路径规划的状态包含的信息比光盘行动要少，因为在光盘行动中我们必须保存一大批布尔值用来表示在给定状态中每个豆子有没有被吃掉。一个世界状态还有可能包含更多的信息，比如吃豆人走过的总距离，或者吃豆人在它的当前位置（x，y）和豆子布尔值上到达过的所有地方这些潜在的编码信息。</p><p>简而言之，世界状态是整个世界中所有的信息，而<strong>搜索状态是对于一个搜索问题其所有需要输入的信息</strong>。</p><h3 id="State-Space-Size-状态空间大小"><a href="#State-Space-Size-状态空间大小" class="headerlink" title="State Space Size 状态空间大小"></a>State Space Size 状态空间大小</h3><p>状态空间大小可以用于<strong>估算搜索问题运行时间</strong>，其唯一计算方法：<br>如果在一个给定的世界里有n个变量分别有$x_1,x_2,x_3…$种不同的取值，那么状态的总数为$x_1x_2x_3x_4…$。</p><p><em><strong>示例</strong></em>：我们用吃豆人来举例说明这个概念，吃豆人有120个位置，前进方向有4个，恶灵有两个，每个恶灵有12个可能位置，共有30个豆子，每个豆子有被吃或未被吃两种状态。则总状态空间大小$120\times4\times12^2\times2^{30}$</p><h3 id="State-Space-Graphs-and-Search-Trees-状态空间图和搜索树"><a href="#State-Space-Graphs-and-Search-Trees-状态空间图和搜索树" class="headerlink" title="State Space Graphs and Search Trees 状态空间图和搜索树"></a>State Space Graphs and Search Trees 状态空间图和搜索树</h3><p>上述示例用了四个部件来完整地定义了一个状态空间。<br><strong>状态空间图（state space graph）</strong> 是由代表状态的结点以及从一个状态指向其后继的有向边构成的。这些边表示操作（action），而任何相关联的权重表示对应操作的代价。每个结点的状态都包括了上述4个元素。<br><strong>注意：</strong> 状态空间图中每个状态只表示一次。</p><p>而对于<strong>搜索树</strong>，其对一个状态的出现次数没有限制。例如，空间图中的极长S → d → e → r → f → G，其在对应搜索树中反映为<strong>从根节点到叶子结点的一个道路</strong>。由于从一个状态到另一个状态通常会有多种方案，搜索树中状态会出现多次。<code>简言之</code>，搜索树中呈现的是搜索路径而不只是结点和结点间关系。<br><img src="https://pic3.zhimg.com/80/v2-4477c7076b96e2ff6609ddcb9e5cfc0e_720w.webp"></p><p>一般在搜索问题中，我们只保存即刻处理的状态，并用相应的后继函数根据需求来计算新的状态。</p><blockquote><p>在树中，我们每次观察那几个非常小心地存储选择的节点，反复地用其后继来替换节点，直到我们到达一个目标状态。</p></blockquote><p>下面将介绍一些方法来决定搜索树中迭代替换结点的顺序（即不同的策略strategy）。</p><h2 id="Uninformed-Search-未知搜索"><a href="#Uninformed-Search-未知搜索" class="headerlink" title="Uninformed Search 未知搜索"></a>Uninformed Search 未知搜索</h2><p>首先介绍<strong>树搜索tree search</strong>：</p><blockquote><p>通过移除一个与部分计划对应的节点（用给定的策略来选择）并用它所有的子节点代替它，我们不断地扩展（expand）我们的边缘(outer fringe)。用子节点代替边缘上的元素,相当于丢弃一个长度为n的计划并考虑所有源于它的长度为（n+1）的计划。我们继续这一操作，直到最终将目标从边缘移除为止。此时我们得出结论，<strong>与移除的目标状态相对应的部分计划其实就是从起始状态到目标状态的一条路径</strong>。</p></blockquote><p>当我们不知道目标状态在搜索树中的的位置时，我们只能从属于<strong>未知搜索（uninformed search）</strong> 的技术中选择用于树搜索的策略。我们将依次介绍<strong>三种策略</strong>：深度优先搜索DFS、广度优先搜索BFS和一致代价搜索UCS，同时包括搜索策略的基本性质，包括完备性、最优性、分支因数h、最大深度m，最浅解深度s</p><h3 id="DFS深度优先搜索"><a href="#DFS深度优先搜索" class="headerlink" title="DFS深度优先搜索"></a>DFS深度优先搜索</h3><p>何为<strong>边缘</strong>，即是当前探索道路的两端（如果不算根的话，即是探索的“头”，多个道路可以有多个头）</p><ul><li><strong>描述</strong>：深度优先搜索DFS总是<strong>选择距离起始节点最深的边缘节点来进行扩展</strong>。DFS选择先访问邻接结点的邻接结点。</li><li><strong>边缘表示</strong>：DFS在边缘将最深结点移除后让最深结点的孩子结点<strong>成为边缘</strong>，此时孩子结点的深度即是<code>原最深结点深度+1</code>。即<strong>边缘中最近添加的对象总有最高优先级</strong>，使用栈（后进先出LIFO）来进行存储。</li><li><strong>完备性</strong>：深度优先搜索<strong>并不具有完备性</strong>。如果在状态空间图中存在回路，这必然意味着相应搜索树的<strong>深度将是无限的</strong>（搜索树是空间图中极长道路组成的，空间图存在回路也就是没有极长道路了）。因此，存在这样一种可能性，即DFS老实地在无限大的搜索树中搜索最深的节点而不幸地陷入僵局，注定无法找到解。</li><li><strong>最优性</strong>：深度优先搜索只是在搜索树中找到“最左边”的解，而没有考虑路径的代价，因此不是最优的。DFS先检索的是邻接表中的第一个邻接结点，<strong>可能有解但不一定是最优解</strong></li><li><strong>时间复杂度</strong>：在最坏情况下，深度优先搜索最终可能会搜遍整个搜索树。</li><li><strong>空间复杂度</strong>：在最坏情况下，DFS在边缘上m个深度级别上都有b个节点。这是一个简单的结果，因为一旦某个父节点的b个子节点进入队列，DFS的本性在任意时间点都只允许研究任意一个子节点的一棵子树。即为$O(bm)$</li></ul><h3 id="BFS广度优先搜索"><a href="#BFS广度优先搜索" class="headerlink" title="BFS广度优先搜索"></a>BFS广度优先搜索</h3><ul><li><strong>描述</strong>：宽度优先搜索总是<strong>选择距离起始节点最浅（近）的边缘节点来扩展</strong>。BFS选择先访问完全所有的邻接结点。</li><li><strong>边缘表示</strong>：如果我们想在较深的节点之前访问较浅的节点，我们必须按照节点的插入顺序来访问它们。使用队列（先进先出FIFO）。</li><li><strong>完备性</strong>：由于总是访问最浅边缘结点，而<strong>最浅结点深度一定是有限的</strong>（在存在解的前提下），故一定可以搜索下去而不会进入死循环，故完备。</li><li><strong>最优性</strong>：BFS一般不是最优的，因为它在选择边缘上被替换的节点时不会考虑代价问题。在所有边的代价都相等的特殊情况下BFS可以保证是最优的，因为这会让BFS退化为一致代价搜索。</li><li><strong>时间复杂度</strong>：遍历所有结点</li><li><strong>空间复杂度</strong>：在最坏情况下，边缘所有节点都在对应最浅解的那一层。（全都要存，都要朝下面找）</li></ul><h3 id="Uniform-Cost-Search-一致代价搜索"><a href="#Uniform-Cost-Search-一致代价搜索" class="headerlink" title="Uniform Cost Search 一致代价搜索"></a>Uniform Cost Search 一致代价搜索</h3><ul><li><strong>描述</strong>：UCS总是选择距离起始节点代价（边权）最小的边缘节点来扩展。</li><li><strong>边缘表示</strong>：UCS的边缘选择用优先堆（<strong>小顶堆</strong>），对于其中的结点v其权重即为从起始节点到v的路径代价，称之为<strong>v的后退代价backward cost</strong>。</li><li><strong>完备性</strong>：如果存在一个目标状态v，它一定有从根到v的有限长度最短路径。故完备</li><li><strong>最优性</strong>：当所有边权非负，UCS是最优的（按照路径代价递增的顺序搜索结点）</li><li><strong>时间复杂度</strong>：<blockquote><p>我们定义最优路径代价为$C^*$，状态空间图内两节点之间最小代价为$\varepsilon$。那么，我们得简单粗暴地遍历深度为从1到$\frac{C^*}{\varepsilon}$范围内的所有节点，导致运行时间为$O\left( b^{\frac{C^*}{\varepsilon}} \right)$。</p></blockquote></li></ul><p>注意：上述三种搜索策略<strong>本质都是树搜索</strong>，只是策略的不同。</p><h2 id="Informed-Search有信息搜索"><a href="#Informed-Search有信息搜索" class="headerlink" title="Informed Search有信息搜索"></a>Informed Search有信息搜索</h2><p>UCS在完备性和最优性上很棒，但时间复杂度较高。如果我们对于我们应该搜索的方向有一定的了解，我们就能显著提高性能并更快地达到目标。这就是有信息搜索。<strong>即已知目标位置，可以估算到目标的距离</strong>。</p><h3 id="Heuristics-启发式搜索"><a href="#Heuristics-启发式搜索" class="headerlink" title="Heuristics 启发式搜索"></a>Heuristics 启发式搜索</h3><p>首先介绍启发式搜索的定义：</p><blockquote><p>Heuristics are the driving force that allow <strong>estimation（估计） of distance to goal states</strong> - they（启发式搜索）’re functions that take in a state as input and output a corresponding estimate. 以一个状态作为输入，以相应的估计为输出。</p></blockquote><p>启发式搜索这种函数是专门用来解决搜索问题的，</p><blockquote><p>we usually want heuristic functions to be a lower bound on this remaining distance to the goal。我们希望启发式搜索可以获得剩余到目标距离的下限，因而启发式搜索通常处理<strong>relaxed problems</strong>。</p></blockquote><p><em><strong>示例</strong></em>：对于前面的路径规划问题，通用解决方法是<strong>曼哈顿距离法Manhattan Distance</strong>。定义两点间曼哈顿距离为：$Manhattan(x_1,y_1,x_2,y_2)&#x3D;|x_1-x_2|+|y_1-y_2|$<br><img src="https://pic4.zhimg.com/80/v2-c3949a1c7834e55745aff852d46447e3_720w.webp" alt="image alt"></p><p>假想要到达左下角，它在计算了<strong>假设没有墙</strong>的情况下从吃豆人现在的位置到目标位置的距离。这个距离是松弛搜索问题中的<strong>精确（exact）距离</strong>，而相应的在实际的搜索问题中计算出的是<strong>估计（estimated）目标距离</strong>。从而实现了为agent<strong>建立“偏好拓展状态”的逻辑</strong>——做决策时总是使得估计结果更接近目标状态</p><blockquote><p>With heuristics, it becomes very easy to implement logic in our agent that enables them to “prefer” expanding states that are estimated to be closer to goal states when deciding which action to perform. </p></blockquote><p>下面讲到的两种搜索策略都是<strong>基于启发式搜索</strong>的原理。</p><h3 id="Greedy-Search贪婪搜索"><a href="#Greedy-Search贪婪搜索" class="headerlink" title="Greedy Search贪婪搜索"></a>Greedy Search贪婪搜索</h3><ul><li><strong>描述</strong>：贪婪搜索总是选择有<strong>最小启发值（lowest heuristic value）</strong> 的节点来扩展，这些节点对应的是它认为最接近目标的状态。<blockquote><p>Greedy search is a strategy for exploration that always selects the frontier node with the lowest heuristic value for expansion</p></blockquote></li><li><strong>边缘描述</strong>：贪婪搜索的操作和UCS相同，具有优先队列边缘表示。但贪婪搜索的堆中各结点用<strong>估计前进代价（estimated forward cost）</strong> 作为结点权值。<blockquote><p>computed backward cost (the sum of edge weights in the path to the state)</p></blockquote></li><li><strong>完备性与最优性</strong>：对于一个目标状态，贪婪搜索<strong>无法保证能找到它，它也不是最优的</strong>，尤其是在选择了非常糟糕的启发函数的情况下。在不同场景中。它的行为通常是不可预测的，有可能一路直奔目标状态，也有可能像一个被错误引导的DFS一样并遍历所有的错误区域。但注意，贪婪搜索有着<strong>高搜索速度</strong><br><img src="https://notes.sjtu.edu.cn/uploads/upload_34b84739b5f2c63a54923c2858179bc0.png"></li></ul><h3 id="A-search-A-搜索"><a href="#A-search-A-搜索" class="headerlink" title="A* search A*搜索"></a>A* search A*搜索</h3><ul><li><p><strong>描述</strong>：A*搜索总是选择有最低估计总代价（lowest estimated total cost）的边缘节点来扩展</p><blockquote><p>A* search is a strategy for exploration that always selects the frontier node with the lowest estimated total cost for expansion, where total cost is the entire cost from the start node to the goal node.其中lowest estimated total cost是指从起始节点到目标节点的全部代价</p></blockquote></li><li><p><strong>边缘表示</strong>：A*搜索也用一个优先队列来表示它的边缘。但A*搜索使用<strong>估计总代价estimated total value</strong>做结点权值，即<code>估计总代价=估计前进代价+后退代价</code></p></li><li><p><strong>完备性与最优性</strong>：在给定一个<strong>合适的启发函数</strong>（我们很快就能得到）时，A*搜索既是完备的又是最优的，兼备贪婪搜索的高搜索速度以及UCS的完备性和最优性。</p></li></ul><h3 id="Admissibility-and-Consistency-可纳性和一致性"><a href="#Admissibility-and-Consistency-可纳性和一致性" class="headerlink" title="Admissibility and Consistency 可纳性和一致性"></a>Admissibility and Consistency 可纳性和一致性</h3><p>接下来我们来花些时间讨论一下一个好的启发式是由什么构成的。下面定义：</p><ul><li>$g(n)$：UCS的总后退代价函数</li><li>$h(n)$：贪婪搜索的启发值函数，即估计前进代价函数</li><li>$f(n)$：A*搜索使用的估计总代价函数。有$f(n)&#x3D;g(n)+h(n)$</li></ul><p>首先要知道，对于A*搜索，其并不是总是保持其完备与最优。例如，启发函数$h(n)&#x3D;1-g(n)$，则此时$f(n)&#x3D;1$，退化为BFS问题（所有目标结点都在同一层级上），而BFS只有在所有边权值一致时才是最优。因此，使用A*搜索，其最优性有条件，称之为<strong>可纳性admissibility</strong></p><blockquote><p>The admissibility constraint（约束） states（表明） that the value estimated by an admissible heuristic is neither negative（负的） nor an overestimate（过估计）.</p></blockquote><h4 id="可纳性约束"><a href="#可纳性约束" class="headerlink" title="可纳性约束"></a>可纳性约束</h4><p>可纳性约束有数学表示：<br>$\forall{n,0}\leq{h(n)}\leq{h^*(n)}$</p><p><strong>定理</strong>：对于一个给定的搜索问题，如果一个启发式函数h满足可纳性约束，使用含有h的A*树搜索能得到最优解<br><strong>证明</strong>：假设两个可以到达的目标状态，最优目标A和次优目标B在一个给定的搜索问题的搜索树中。因为可以从初始状态到达A，A的某个祖先节点n（有可能是A本身）现在一定在边缘上。用以下三个陈述，我们可以断定n会在B之前被选来扩展</p>]]></content>
    
    
    <categories>
      
      <category>笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>笔记</tag>
      
      <tag>AI</tag>
      
      <tag>Basic</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
